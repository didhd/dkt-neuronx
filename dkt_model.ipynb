{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "introduction",
   "metadata": {},
   "source": [
    "# Deep Knowledge Tracing (DKT) Implemetation\n",
    "\n",
    "## Introduction\n",
    " Deep Knowledge Tracing (DKT) is a deep learning-based methodology for tracking students' knowledge states in educational settings. Unlike traditional Knowledge Tracing, DKT uses Recurrent Neural Networks (RNN) to model student learning processes. This allows prediction of the probability that a student can solve specific problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-environment",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "AWS Inferentia2 (INF2) is an accelerator specifically designed for deep learning inference. We install the necessary libraries to utilize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-packages",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: torch-neuronx in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (1.13.1.1.16.0)\n",
      "Collecting torch-neuronx\n",
      "  Using cached https://pip.repos.neuron.amazonaws.com/torch-neuronx/torch_neuronx-2.1.2.2.3.2-py3-none-any.whl (2.6 MB)\n",
      "Requirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (0.14.1)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.19.1-cp38-cp38-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: neuronx-cc[tensorflow] in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (2.15.143.0+e39249ad)\n",
      "Collecting torch==2.1.* (from torch-neuronx)\n",
      "  Using cached torch-2.1.2-cp38-cp38-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "INFO: pip is looking at multiple versions of torch-neuronx to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torch-neuronx\n",
      "  Using cached https://pip.repos.neuron.amazonaws.com/torch-neuronx/torch_neuronx-2.1.2.2.3.1-py3-none-any.whl (2.6 MB)\n",
      "  Using cached https://pip.repos.neuron.amazonaws.com/torch-neuronx/torch_neuronx-2.1.2.2.3.0-py3-none-any.whl (2.6 MB)\n",
      "  Using cached https://pip.repos.neuron.amazonaws.com/torch-neuronx/torch_neuronx-2.1.2.2.2.0-py3-none-any.whl (2.5 MB)\n",
      "  Using cached https://pip.repos.neuron.amazonaws.com/torch-neuronx/torch_neuronx-2.1.2.2.1.0-py3-none-any.whl (2.5 MB)\n",
      "Requirement already satisfied: torch==1.13.* in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from torch-neuronx) (1.13.1)\n",
      "Requirement already satisfied: torch-xla==1.13.1+torchneurong in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from torch-neuronx) (1.13.1+torchneurong)\n",
      "Requirement already satisfied: libneuronxla==0.5.2978 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from torch-neuronx) (0.5.2978)\n",
      "Requirement already satisfied: setuptools<=69.5.1 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from torch-neuronx) (69.5.1)\n",
      "Requirement already satisfied: protobuf>3.19 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from torch-neuronx) (3.20.3)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from torch-neuronx) (1.24.4)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from torch-neuronx) (6.1.0)\n",
      "Requirement already satisfied: aws-neuronx-runtime-discovery~=2.0 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from libneuronxla==0.5.2978->torch-neuronx) (2.9)\n",
      "Requirement already satisfied: boto3~=1.26 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from libneuronxla==0.5.2978->torch-neuronx) (1.35.61)\n",
      "Requirement already satisfied: botocore~=1.29 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from libneuronxla==0.5.2978->torch-neuronx) (1.35.61)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from torch==1.13.*->torch-neuronx) (4.12.2)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from torch==1.13.*->torch-neuronx) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from torch==1.13.*->torch-neuronx) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from torch==1.13.*->torch-neuronx) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from torch==1.13.*->torch-neuronx) (11.7.99)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from torch-xla==1.13.1+torchneurong->torch-neuronx) (2.1.0)\n",
      "Requirement already satisfied: cloud-tpu-client>=0.10.0 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from torch-xla==1.13.1+torchneurong->torch-neuronx) (0.10)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from torch-xla==1.13.1+torchneurong->torch-neuronx) (6.0.2)\n",
      "Requirement already satisfied: wheel in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.*->torch-neuronx) (0.45.0)\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.19.0-cp38-cp38-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
      "  Using cached torchvision-0.18.1-cp38-cp38-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "  Using cached torchvision-0.18.0-cp38-cp38-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "  Using cached torchvision-0.17.2-cp38-cp38-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "  Using cached torchvision-0.17.1-cp38-cp38-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "  Using cached torchvision-0.17.0-cp38-cp38-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from torchvision) (2.31.0)\n",
      "  Using cached torchvision-0.16.2-cp38-cp38-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "INFO: pip is still looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached torchvision-0.16.1-cp38-cp38-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "  Using cached torchvision-0.16.0-cp38-cp38-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "  Using cached torchvision-0.15.2-cp38-cp38-manylinux1_x86_64.whl.metadata (11 kB)\n",
      "  Using cached torchvision-0.15.1-cp38-cp38-manylinux1_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from torchvision) (10.4.0)\n",
      "\u001b[33mWARNING: neuronx-cc 2.15.143.0+e39249ad does not provide the extra 'tensorflow'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: networkx~=2.6 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from neuronx-cc[tensorflow]) (2.8.8)\n",
      "Requirement already satisfied: scipy<=1.11.2 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from neuronx-cc[tensorflow]) (1.10.1)\n",
      "Requirement already satisfied: python-daemon>=2.2.4 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from neuronx-cc[tensorflow]) (3.1.0)\n",
      "Requirement already satisfied: requests-unixsocket>=0.1.5 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from neuronx-cc[tensorflow]) (0.3.0)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from neuronx-cc[tensorflow]) (0.2.0)\n",
      "Requirement already satisfied: islpy~=2023.1 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from neuronx-cc[tensorflow]) (2023.2.5)\n",
      "Requirement already satisfied: pgzip>=0.3.0 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from neuronx-cc[tensorflow]) (0.3.5)\n",
      "Requirement already satisfied: ec2-metadata~=2.10 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from neuronx-cc[tensorflow]) (2.13.0)\n",
      "Requirement already satisfied: tqdm>=4 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from neuronx-cc[tensorflow]) (4.67.0)\n",
      "Requirement already satisfied: lockfile>=0.10 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from python-daemon>=2.2.4->neuronx-cc[tensorflow]) (0.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from requests->torchvision) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from requests->torchvision) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from requests->torchvision) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from requests->torchvision) (2024.8.30)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from boto3~=1.26->libneuronxla==0.5.2978->torch-neuronx) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from boto3~=1.26->libneuronxla==0.5.2978->torch-neuronx) (0.10.3)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from botocore~=1.29->libneuronxla==0.5.2978->torch-neuronx) (2.9.0.post0)\n",
      "Requirement already satisfied: google-api-python-client==1.8.0 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from cloud-tpu-client>=0.10.0->torch-xla==1.13.1+torchneurong->torch-neuronx) (1.8.0)\n",
      "Requirement already satisfied: oauth2client in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from cloud-tpu-client>=0.10.0->torch-xla==1.13.1+torchneurong->torch-neuronx) (4.1.3)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==1.13.1+torchneurong->torch-neuronx) (0.22.0)\n",
      "Requirement already satisfied: google-auth>=1.4.1 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==1.13.1+torchneurong->torch-neuronx) (2.36.0)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==1.13.1+torchneurong->torch-neuronx) (0.2.0)\n",
      "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==1.13.1+torchneurong->torch-neuronx) (1.34.1)\n",
      "Requirement already satisfied: six<2dev,>=1.6.1 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==1.13.1+torchneurong->torch-neuronx) (1.16.0)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==1.13.1+torchneurong->torch-neuronx) (3.0.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from oauth2client->cloud-tpu-client>=0.10.0->torch-xla==1.13.1+torchneurong->torch-neuronx) (0.6.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from oauth2client->cloud-tpu-client>=0.10.0->torch-xla==1.13.1+torchneurong->torch-neuronx) (0.4.1)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from oauth2client->cloud-tpu-client>=0.10.0->torch-xla==1.13.1+torchneurong->torch-neuronx) (4.7.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==1.13.1+torchneurong->torch-neuronx) (1.66.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==1.13.1+torchneurong->torch-neuronx) (5.5.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from httplib2<1dev,>=0.9.2->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==1.13.1+torchneurong->torch-neuronx) (3.1.4)\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (1.24.4)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (2.0.3)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (1.3.2)\n",
      "Requirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (3.7.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from matplotlib) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from matplotlib) (6.4.5)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.20.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Install Neuron SDK and PyTorch NeuronX\n",
    "!pip install torch-neuronx torchvision neuronx-cc[tensorflow] -U\n",
    "\n",
    "# Install other required packages \n",
    "!pip install numpy pandas scikit-learn matplotlib -U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "import-libraries",
   "metadata": {},
   "source": [
    "## Library Import\n",
    "\n",
    "Import required libraries.\n",
    "- numpy: Basic library for numerical operations \n",
    "- pandas: Data processing and analysis\n",
    "- torch: Deep learning model implementation\n",
    "- torch_neuronx: AWS Inferentia2 optimization\n",
    "- sklearn: Performance evaluation and data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "import-libs",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_neuronx\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-data",
   "metadata": {},
   "source": [
    "## Dataset Introduction\n",
    "The ASSISTments 2009 dataset is a widely used public dataset in educational data mining with these characteristics:\n",
    "- Students' mathematics problem-solving records\n",
    "- Information including problem ID, student ID, correctness\n",
    "- Data collected from real educational environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-dataset",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>assignment_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>assistment_id</th>\n",
       "      <th>problem_id</th>\n",
       "      <th>original</th>\n",
       "      <th>correct</th>\n",
       "      <th>attempt_count</th>\n",
       "      <th>ms_first_response</th>\n",
       "      <th>tutor_mode</th>\n",
       "      <th>...</th>\n",
       "      <th>hint_count</th>\n",
       "      <th>hint_total</th>\n",
       "      <th>overlap_time</th>\n",
       "      <th>template_id</th>\n",
       "      <th>answer_id</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>first_action</th>\n",
       "      <th>bottom_hint</th>\n",
       "      <th>opportunity</th>\n",
       "      <th>opportunity_original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33022537</td>\n",
       "      <td>277618</td>\n",
       "      <td>64525</td>\n",
       "      <td>33139</td>\n",
       "      <td>51424</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32454</td>\n",
       "      <td>tutor</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32454</td>\n",
       "      <td>30799</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33022709</td>\n",
       "      <td>277618</td>\n",
       "      <td>64525</td>\n",
       "      <td>33150</td>\n",
       "      <td>51435</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4922</td>\n",
       "      <td>tutor</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4922</td>\n",
       "      <td>30799</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35450204</td>\n",
       "      <td>220674</td>\n",
       "      <td>70363</td>\n",
       "      <td>33159</td>\n",
       "      <td>51444</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>25390</td>\n",
       "      <td>tutor</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>42000</td>\n",
       "      <td>30799</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35450295</td>\n",
       "      <td>220674</td>\n",
       "      <td>70363</td>\n",
       "      <td>33110</td>\n",
       "      <td>51395</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4859</td>\n",
       "      <td>tutor</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4859</td>\n",
       "      <td>30059</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35450311</td>\n",
       "      <td>220674</td>\n",
       "      <td>70363</td>\n",
       "      <td>33196</td>\n",
       "      <td>51481</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>19813</td>\n",
       "      <td>tutor</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>124564</td>\n",
       "      <td>30060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id  assignment_id  user_id  assistment_id  problem_id  original  \\\n",
       "0  33022537         277618    64525          33139       51424         1   \n",
       "1  33022709         277618    64525          33150       51435         1   \n",
       "2  35450204         220674    70363          33159       51444         1   \n",
       "3  35450295         220674    70363          33110       51395         1   \n",
       "4  35450311         220674    70363          33196       51481         1   \n",
       "\n",
       "   correct  attempt_count  ms_first_response tutor_mode  ... hint_count  \\\n",
       "0        1              1              32454      tutor  ...          0   \n",
       "1        1              1               4922      tutor  ...          0   \n",
       "2        0              2              25390      tutor  ...          0   \n",
       "3        1              1               4859      tutor  ...          0   \n",
       "4        0             14              19813      tutor  ...          3   \n",
       "\n",
       "   hint_total  overlap_time  template_id answer_id  answer_text  first_action  \\\n",
       "0           3         32454        30799       NaN           26             0   \n",
       "1           3          4922        30799       NaN           55             0   \n",
       "2           3         42000        30799       NaN           88             0   \n",
       "3           3          4859        30059       NaN           41             0   \n",
       "4           4        124564        30060       NaN           65             0   \n",
       "\n",
       "  bottom_hint  opportunity  opportunity_original  \n",
       "0         NaN            1                   1.0  \n",
       "1         NaN            2                   2.0  \n",
       "2         NaN            1                   1.0  \n",
       "3         NaN            2                   2.0  \n",
       "4         0.0            3                   3.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set dataset path (change to actual path)\n",
    "data_path = 'datasets/ASSIST2009/skill_builder_data.csv'\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv(data_path, encoding='ISO-8859-1', low_memory=False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-preprocessing",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "Preprocess the data into the format required for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-preprocess-code",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학생 수: 4217\n",
      "문제 수: 26688\n"
     ]
    }
   ],
   "source": [
    "# Select required columns\n",
    "data = data[['user_id', 'problem_id', 'correct']]\n",
    "\n",
    "# Remove missing values\n",
    "data = data.dropna()\n",
    "\n",
    "# ID encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "user_encoder = LabelEncoder()\n",
    "data['user_id'] = user_encoder.fit_transform(data['user_id'])\n",
    "\n",
    "item_encoder = LabelEncoder()\n",
    "data['problem_id'] = item_encoder.fit_transform(data['problem_id'])\n",
    "\n",
    "# Check number of problems and students\n",
    "num_students = data['user_id'].nunique()\n",
    "num_questions = data['problem_id'].nunique()\n",
    "\n",
    "print(f'Number of students: {num_students}')\n",
    "print(f'Number of problems: {num_questions}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sequence-generation",
   "metadata": {},
   "source": [
    "### Create Sequence Data\n",
    "\n",
    "Create sequences of problem-solving history for each student."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sequence-gen-code",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 시퀀스 수: 4217\n"
     ]
    }
   ],
   "source": [
    "# Group by student\n",
    "grouped = data.groupby('user_id')\n",
    "\n",
    "# Generate sequences\n",
    "sequences = []\n",
    "\n",
    "for _, group in grouped:\n",
    "    seq = list(zip(group['problem_id'].values, group['correct'].values))\n",
    "    sequences.append(seq)\n",
    "\n",
    "print(f'Total number of sequences: {len(sequences)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dataset-dataloader",
   "metadata": {},
   "source": [
    "### Configure Dataset and DataLoader\n",
    "\n",
    "Define PyTorch Dataset and DataLoader for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dataset-code",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DKTDataset(Dataset):\n",
    "    def __init__(self, sequences, num_questions, seq_len=100):\n",
    "        self.sequences = sequences\n",
    "        self.num_questions = num_questions\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.sequences[idx]\n",
    "        \n",
    "        seq = seq[-self.seq_len:]\n",
    "        \n",
    "        x = np.zeros(self.seq_len, dtype=int)\n",
    "        y = np.zeros(self.seq_len, dtype=int)\n",
    "        \n",
    "        for i, (q, r) in enumerate(seq):\n",
    "            x[i] = q + self.num_questions * r\n",
    "            y[i] = q\n",
    "        \n",
    "        return torch.tensor(x, dtype=torch.long), torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "# Create dataset\n",
    "dataset = DKTDataset(sequences, num_questions)\n",
    "\n",
    "# Split into training and test sets\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create DataLoader\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "define-model",
   "metadata": {},
   "source": [
    "## DKT Model Architecture\n",
    "The DKT model consists of the following structure:\n",
    "1. Embedding Layer: Converts problem IDs to vectors\n",
    "2. LSTM Layer: Processes sequence data\n",
    "3. Output Layer: Predicts probability of correct answers\n",
    "\n",
    "The DKT model is based on LSTM (Long Short-Term Memory) neural networks and takes a student's past problem-solving history as input to predict the probability of correct answers for the next problem. We define a DKT model based on LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "model-definition",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DKTModel(nn.Module):\n",
    "    def __init__(self, num_questions, hidden_size):\n",
    "        super(DKTModel, self).__init__()\n",
    "        self.num_questions = num_questions\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(num_questions * 2, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_questions)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        embed = self.embedding(x)\n",
    "        h, _ = self.lstm(embed)\n",
    "        out = self.fc(h)\n",
    "        preds = torch.sigmoid(out)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train-model",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "Write code to train the model. Considerations during training:\n",
    "- Batch size selection\n",
    "- Learning rate adjustment  \n",
    "- Loss function (BCE Loss)\n",
    "- Optimizer (Adam)\n",
    "- Number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-code",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.6603\n",
      "Epoch [2/10], Loss: 0.5177\n",
      "Epoch [3/10], Loss: 0.2917\n",
      "Epoch [4/10], Loss: 0.1760\n",
      "Epoch [5/10], Loss: 0.1177\n",
      "Epoch [6/10], Loss: 0.0840\n",
      "Epoch [7/10], Loss: 0.0631\n",
      "Epoch [8/10], Loss: 0.0489\n",
      "Epoch [9/10], Loss: 0.0390\n",
      "Epoch [10/10], Loss: 0.0319\n"
     ]
    }
   ],
   "source": [
    "# Set device (CPU for INF2)\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# Set hyperparameters\n",
    "num_epochs = 10\n",
    "hidden_size = 100\n",
    "\n",
    "# Initialize model\n",
    "model = DKTModel(num_questions, hidden_size).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "train_losses = []\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for x, y in train_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(x)\n",
    "        \n",
    "        # Create targets\n",
    "        target_mask = (y != 0)\n",
    "        target_indices = y[target_mask]\n",
    "        \n",
    "        preds = preds[target_mask, target_indices]\n",
    "        targets = (x[target_mask] >= num_questions).float()\n",
    "        \n",
    "        loss = criterion(preds, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "\n",
    "# Save trained model\n",
    "torch.save(model.state_dict(), 'dkt_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compile-model",
   "metadata": {},
   "source": [
    "## Model Compilation (Neuron Optimization)\n",
    "\n",
    "Compile the trained model using `torch_neuronx` for inference on INF2.\n",
    "\n",
    "The reasons for creating example_inputs are:\n",
    "\n",
    "1. **Define Input Shape for Model Compilation**\n",
    "   - torch_neuronx.trace() function needs to know the specific shape and data type of input tensors to compile the model into an AWS Inferentia2 optimized form\n",
    "   - Example inputs inform the model about the structure of data it will actually receive\n",
    "\n",
    "2. **Compilation Optimization**\n",
    "   ```python\n",
    "   example_inputs = torch.randint(0, num_questions * 2, (batch_size, 100), dtype=torch.long)\n",
    "   ```\n",
    "   - batch_size: Number of data to process at once (64 here)\n",
    "   - 100: Sequence length\n",
    "   - num_questions * 2: Range of possible input values (combination of problem ID and correctness)\n",
    "\n",
    "3. **Execution Graph Generation**\n",
    "   - The compiler uses these example inputs to optimize the model's computation graph\n",
    "   - Analyzes and optimizes computation patterns that will be used in actual inference\n",
    "\n",
    "4. **Hardware Optimization**\n",
    "   ```python\n",
    "   model_neuron = torch_neuronx.trace(model, example_inputs)\n",
    "   ```\n",
    "   - Optimizes computations for AWS Inferentia2 hardware\n",
    "   - Improves memory usage and computation speed\n",
    "\n",
    "Example:\n",
    "```python\n",
    "# For actual batch size of 64 and sequence length of 100\n",
    "batch_size = 64\n",
    "seq_length = 100\n",
    "num_questions = 100  # Total number of problems\n",
    "\n",
    "# Create example inputs\n",
    "example_inputs = torch.randint(\n",
    "    low=0,  # minimum value\n",
    "    high=num_questions * 2,  # maximum value (num_questions * 2)\n",
    "    size=(batch_size, seq_length),  # input tensor size\n",
    "    dtype=torch.long  # data type\n",
    ")\n",
    "\n",
    "# Compile model with these example inputs\n",
    "model_neuron = torch_neuronx.trace(model, example_inputs)\n",
    "```\n",
    "\n",
    "While these example inputs are dummy data rather than actual data, they contain all the structural information needed for model compilation and optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compile-code",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-25 14:22:00.000511:  18793  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-11-25 14:22:00.000512:  18793  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: ['neuronx-cc', '--target=trn1', 'compile', '--framework', 'XLA', '/tmp/ec2-user/neuroncc_compile_workdir/f1751cb8-0a67-4cb8-bc6a-c417a2e51eee/model.MODULE_10466109672838001554+d41d8cd9.hlo.pb', '--output', '/tmp/ec2-user/neuroncc_compile_workdir/f1751cb8-0a67-4cb8-bc6a-c417a2e51eee/model.MODULE_10466109672838001554+d41d8cd9.neff', '--verbose=35']\n",
      ".\n",
      "Compiler status PASS\n",
      "2024-11-25 14:22:02.000881:  18863  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-11-25 14:22:02.000882:  18863  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: ['neuronx-cc', '--target=trn1', 'compile', '--framework', 'XLA', '/tmp/ec2-user/neuroncc_compile_workdir/20158125-f6fd-4581-b4a0-c79305a82d2d/model.MODULE_10076059576887794638+d41d8cd9.hlo.pb', '--output', '/tmp/ec2-user/neuroncc_compile_workdir/20158125-f6fd-4581-b4a0-c79305a82d2d/model.MODULE_10076059576887794638+d41d8cd9.neff', '--verbose=35']\n",
      ".\n",
      "Compiler status PASS\n",
      "2024-11-25 14:22:04.000456:  18927  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-11-25 14:22:04.000457:  18927  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: ['neuronx-cc', '--target=trn1', 'compile', '--framework', 'XLA', '/tmp/ec2-user/neuroncc_compile_workdir/7deb959a-dcb1-484b-83d2-b0474aaf9a39/model.MODULE_12064476461908315021+d41d8cd9.hlo.pb', '--output', '/tmp/ec2-user/neuroncc_compile_workdir/7deb959a-dcb1-484b-83d2-b0474aaf9a39/model.MODULE_12064476461908315021+d41d8cd9.neff', '--verbose=35']\n",
      ".\n",
      "Compiler status PASS\n",
      "2024-11-25 14:22:06.000086:  18997  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-11-25 14:22:06.000087:  18997  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: ['neuronx-cc', '--target=trn1', 'compile', '--framework', 'XLA', '/tmp/ec2-user/neuroncc_compile_workdir/64915eb1-3194-40c0-b6e7-4d1e75838fad/model.MODULE_12957766554152477008+d41d8cd9.hlo.pb', '--output', '/tmp/ec2-user/neuroncc_compile_workdir/64915eb1-3194-40c0-b6e7-4d1e75838fad/model.MODULE_12957766554152477008+d41d8cd9.neff', '--verbose=35']\n",
      ".\n",
      "Compiler status PASS\n",
      "2024-11-25 14:22:07.000771:  19052  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-11-25 14:22:07.000772:  19052  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: ['neuronx-cc', '--target=trn1', 'compile', '--framework', 'XLA', '/tmp/ec2-user/neuroncc_compile_workdir/87359081-869d-4e48-aa93-d06c036b3e20/model.MODULE_16164033684040262538+d41d8cd9.hlo.pb', '--output', '/tmp/ec2-user/neuroncc_compile_workdir/87359081-869d-4e48-aa93-d06c036b3e20/model.MODULE_16164033684040262538+d41d8cd9.neff', '--verbose=35']\n",
      ".\n",
      "Compiler status PASS\n",
      ".....\n",
      "Compiler status PASS\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model.load_state_dict(torch.load('dkt_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Create example inputs\n",
    "example_inputs = torch.randint(0, num_questions * 2, (batch_size, 100), dtype=torch.long)\n",
    "\n",
    "# Compile with Neuron\n",
    "model_neuron = torch_neuronx.trace(model, example_inputs)\n",
    "\n",
    "# Save compiled model\n",
    "model_neuron.save('dkt_model_neuron.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inference",
   "metadata": {},
   "source": [
    "## Performance Evaluation\n",
    "\n",
    "Perform inference on INF2 using the compiled model. The DKT model's performance is evaluated using the following metrics:\n",
    "- AUC (Area Under the ROC Curve)\n",
    "- Accuracy\n",
    "- Changes in loss function values\n",
    "\n",
    "When running the model on AWS Inferentia hardware, the input tensor size must exactly match the size specified during compilation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inference-code",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[테스트 통계]\n",
      "총 시퀀스 수: 832\n",
      "총 문제 수: 35537\n",
      "시퀀스당 평균 문제 수: 42.71\n",
      "전체 데이터 크기: 35537\n",
      "\n",
      "테스트 성능:\n",
      "AUC: 99.17%\n"
     ]
    }
   ],
   "source": [
    "# Load compiled model\n",
    "model_neuron = torch.jit.load('dkt_model_neuron.pt')\n",
    "model_neuron.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "total_samples = 0\n",
    "total_sequences = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (x, y) in enumerate(test_loader):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        preds = model_neuron(x)\n",
    "        \n",
    "        batch_samples = 0\n",
    "        for i in range(len(y)):\n",
    "            target_mask = (y[i] != 0)\n",
    "            target_indices = y[i][target_mask]\n",
    "            pred = preds[i][target_mask, target_indices]\n",
    "            \n",
    "            # Calculate actual number of problems in current sequence\n",
    "            num_problems = len(target_indices)\n",
    "            batch_samples += num_problems\n",
    "            \n",
    "            all_preds.extend(pred.cpu().numpy())\n",
    "            all_targets.extend((x[i][target_mask] >= num_questions).cpu().numpy())\n",
    "        \n",
    "        total_samples += batch_samples\n",
    "        total_sequences += len(y)\n",
    "\n",
    "print(f'\\n[Test Statistics]')\n",
    "print(f'Total sequences: {total_sequences}')\n",
    "print(f'Total problems: {total_samples}')\n",
    "print(f'Average problems per sequence: {total_samples/total_sequences:.2f}')\n",
    "print(f'Total data size: {len(all_preds)}')\n",
    "\n",
    "# Performance evaluation\n",
    "auc = roc_auc_score(all_targets, all_preds)\n",
    "print(f'\\nTest Performance:')\n",
    "print(f'AUC: {auc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we implemented the DKT model using PyTorch and AWS Inferentia2, and performed inference on INF2 using `torch-neuronx`. We provided step-by-step explanations that even beginners can understand, and achieved efficient inference by leveraging INF2's performance capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "references",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [Deep Knowledge Tracing Paper](https://papers.nips.cc/paper/2015/file/efc3f4b5768f887a677ce7f1dba75504-Paper.pdf)\n",
    "- [ASSISTments Dataset](https://sites.google.com/site/assistmentsdata/home/assistment-2009-2010-data)\n",
    "- [AWS Neuron SDK Documentation](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/neuron-guide/neuron-frameworks/pytorch-neuronx/tutorials/torch-neuronx.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_neuron_pytorch_p38",
   "language": "python",
   "name": "conda_neuron_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
