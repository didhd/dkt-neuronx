{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "introduction",
   "metadata": {},
   "source": [
    "# Deep Knowledge Tracing (DKT) 구현\n",
    "\n",
    "## 소개\n",
    "Deep Knowledge Tracing(DKT)은 교육 분야에서 학생들의 지식 상태를 추적하는 딥러닝 기반 방법론입니다. 전통적인 Knowledge Tracing과 달리, DKT는 순환 신경망(RNN)을 사용하여 학생의 학습 과정을 모델링합니다. 이를 통해 학생이 특정 문제를 해결할 수 있는 확률을 예측할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-environment",
   "metadata": {},
   "source": [
    "## 환경 설정\n",
    "AWS Inferentia2(INF2)는 딥러닝 추론을 위해 특별히 설계된 가속기입니다. 이를 활용하기 위해 필요한 라이브러리들을 설치합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "install-packages",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: torch-neuronx in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (1.13.1.1.16.0)\n",
      "Collecting torch-neuronx\n",
      "  Using cached https://pip.repos.neuron.amazonaws.com/torch-neuronx/torch_neuronx-2.1.2.2.3.2-py3-none-any.whl (2.6 MB)\n",
      "Requirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (0.14.1)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.19.1-cp38-cp38-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: neuronx-cc[tensorflow] in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (2.15.143.0+e39249ad)\n",
      "Collecting torch==2.1.* (from torch-neuronx)\n",
      "  Using cached torch-2.1.2-cp38-cp38-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "INFO: pip is looking at multiple versions of torch-neuronx to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torch-neuronx\n",
      "  Using cached https://pip.repos.neuron.amazonaws.com/torch-neuronx/torch_neuronx-2.1.2.2.3.1-py3-none-any.whl (2.6 MB)\n",
      "  Using cached https://pip.repos.neuron.amazonaws.com/torch-neuronx/torch_neuronx-2.1.2.2.3.0-py3-none-any.whl (2.6 MB)\n",
      "  Using cached https://pip.repos.neuron.amazonaws.com/torch-neuronx/torch_neuronx-2.1.2.2.2.0-py3-none-any.whl (2.5 MB)\n",
      "  Using cached https://pip.repos.neuron.amazonaws.com/torch-neuronx/torch_neuronx-2.1.2.2.1.0-py3-none-any.whl (2.5 MB)\n",
      "Requirement already satisfied: torch==1.13.* in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from torch-neuronx) (1.13.1)\n",
      "Requirement already satisfied: torch-xla==1.13.1+torchneurong in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from torch-neuronx) (1.13.1+torchneurong)\n",
      "Requirement already satisfied: libneuronxla==0.5.2978 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from torch-neuronx) (0.5.2978)\n",
      "Requirement already satisfied: setuptools<=69.5.1 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from torch-neuronx) (69.5.1)\n",
      "Requirement already satisfied: protobuf>3.19 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from torch-neuronx) (3.20.3)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from torch-neuronx) (1.24.4)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from torch-neuronx) (6.1.0)\n",
      "Requirement already satisfied: aws-neuronx-runtime-discovery~=2.0 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from libneuronxla==0.5.2978->torch-neuronx) (2.9)\n",
      "Requirement already satisfied: boto3~=1.26 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from libneuronxla==0.5.2978->torch-neuronx) (1.35.61)\n",
      "Requirement already satisfied: botocore~=1.29 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from libneuronxla==0.5.2978->torch-neuronx) (1.35.61)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from torch==1.13.*->torch-neuronx) (4.12.2)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from torch==1.13.*->torch-neuronx) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from torch==1.13.*->torch-neuronx) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from torch==1.13.*->torch-neuronx) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from torch==1.13.*->torch-neuronx) (11.7.99)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from torch-xla==1.13.1+torchneurong->torch-neuronx) (2.1.0)\n",
      "Requirement already satisfied: cloud-tpu-client>=0.10.0 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from torch-xla==1.13.1+torchneurong->torch-neuronx) (0.10)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from torch-xla==1.13.1+torchneurong->torch-neuronx) (6.0.2)\n",
      "Requirement already satisfied: wheel in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.*->torch-neuronx) (0.45.0)\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.19.0-cp38-cp38-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
      "  Using cached torchvision-0.18.1-cp38-cp38-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "  Using cached torchvision-0.18.0-cp38-cp38-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "  Using cached torchvision-0.17.2-cp38-cp38-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "  Using cached torchvision-0.17.1-cp38-cp38-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "  Using cached torchvision-0.17.0-cp38-cp38-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from torchvision) (2.31.0)\n",
      "  Using cached torchvision-0.16.2-cp38-cp38-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "INFO: pip is still looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached torchvision-0.16.1-cp38-cp38-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "  Using cached torchvision-0.16.0-cp38-cp38-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "  Using cached torchvision-0.15.2-cp38-cp38-manylinux1_x86_64.whl.metadata (11 kB)\n",
      "  Using cached torchvision-0.15.1-cp38-cp38-manylinux1_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from torchvision) (10.4.0)\n",
      "\u001b[33mWARNING: neuronx-cc 2.15.143.0+e39249ad does not provide the extra 'tensorflow'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: networkx~=2.6 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from neuronx-cc[tensorflow]) (2.8.8)\n",
      "Requirement already satisfied: scipy<=1.11.2 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from neuronx-cc[tensorflow]) (1.10.1)\n",
      "Requirement already satisfied: python-daemon>=2.2.4 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from neuronx-cc[tensorflow]) (3.1.0)\n",
      "Requirement already satisfied: requests-unixsocket>=0.1.5 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from neuronx-cc[tensorflow]) (0.3.0)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from neuronx-cc[tensorflow]) (0.2.0)\n",
      "Requirement already satisfied: islpy~=2023.1 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from neuronx-cc[tensorflow]) (2023.2.5)\n",
      "Requirement already satisfied: pgzip>=0.3.0 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from neuronx-cc[tensorflow]) (0.3.5)\n",
      "Requirement already satisfied: ec2-metadata~=2.10 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from neuronx-cc[tensorflow]) (2.13.0)\n",
      "Requirement already satisfied: tqdm>=4 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from neuronx-cc[tensorflow]) (4.67.0)\n",
      "Requirement already satisfied: lockfile>=0.10 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from python-daemon>=2.2.4->neuronx-cc[tensorflow]) (0.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from requests->torchvision) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from requests->torchvision) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from requests->torchvision) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from requests->torchvision) (2024.8.30)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from boto3~=1.26->libneuronxla==0.5.2978->torch-neuronx) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from boto3~=1.26->libneuronxla==0.5.2978->torch-neuronx) (0.10.3)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from botocore~=1.29->libneuronxla==0.5.2978->torch-neuronx) (2.9.0.post0)\n",
      "Requirement already satisfied: google-api-python-client==1.8.0 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from cloud-tpu-client>=0.10.0->torch-xla==1.13.1+torchneurong->torch-neuronx) (1.8.0)\n",
      "Requirement already satisfied: oauth2client in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from cloud-tpu-client>=0.10.0->torch-xla==1.13.1+torchneurong->torch-neuronx) (4.1.3)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==1.13.1+torchneurong->torch-neuronx) (0.22.0)\n",
      "Requirement already satisfied: google-auth>=1.4.1 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==1.13.1+torchneurong->torch-neuronx) (2.36.0)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==1.13.1+torchneurong->torch-neuronx) (0.2.0)\n",
      "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==1.13.1+torchneurong->torch-neuronx) (1.34.1)\n",
      "Requirement already satisfied: six<2dev,>=1.6.1 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==1.13.1+torchneurong->torch-neuronx) (1.16.0)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==1.13.1+torchneurong->torch-neuronx) (3.0.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from oauth2client->cloud-tpu-client>=0.10.0->torch-xla==1.13.1+torchneurong->torch-neuronx) (0.6.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from oauth2client->cloud-tpu-client>=0.10.0->torch-xla==1.13.1+torchneurong->torch-neuronx) (0.4.1)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from oauth2client->cloud-tpu-client>=0.10.0->torch-xla==1.13.1+torchneurong->torch-neuronx) (4.7.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==1.13.1+torchneurong->torch-neuronx) (1.66.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==1.13.1+torchneurong->torch-neuronx) (5.5.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from httplib2<1dev,>=0.9.2->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==1.13.1+torchneurong->torch-neuronx) (3.1.4)\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (1.24.4)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (2.0.3)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (1.3.2)\n",
      "Requirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (3.7.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from matplotlib) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from matplotlib) (6.4.5)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.20.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Neuron SDK 및 PyTorch NeuronX 설치\n",
    "!pip install torch-neuronx torchvision neuronx-cc[tensorflow] -U\n",
    "\n",
    "# 기타 필요한 패키지 설치\n",
    "!pip install numpy pandas scikit-learn matplotlib -U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "import-libraries",
   "metadata": {},
   "source": [
    "## 라이브러리 임포트\n",
    "\n",
    "필요한 라이브러리를 임포트합니다.\n",
    "- numpy: 수치 연산을 위한 기본 라이브러리\n",
    "- pandas: 데이터 처리 및 분석\n",
    "- torch: 딥러닝 모델 구현\n",
    "- torch_neuronx: AWS Inferentia2 최적화\n",
    "- sklearn: 성능 평가 및 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "import-libs",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_neuronx\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-data",
   "metadata": {},
   "source": [
    "## 데이터셋 소개\n",
    "ASSISTments 2009 데이터셋은 교육 데이터 마이닝 분야에서 널리 사용되는 공개 데이터셋입니다. 이 데이터셋은 다음과 같은 특징을 가집니다:\n",
    "- 학생들의 수학 문제 풀이 기록\n",
    "- 문제 ID, 학생 ID, 정답 여부 등의 정보 포함\n",
    "- 실제 교육 환경에서 수집된 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "load-dataset",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>assignment_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>assistment_id</th>\n",
       "      <th>problem_id</th>\n",
       "      <th>original</th>\n",
       "      <th>correct</th>\n",
       "      <th>attempt_count</th>\n",
       "      <th>ms_first_response</th>\n",
       "      <th>tutor_mode</th>\n",
       "      <th>...</th>\n",
       "      <th>hint_count</th>\n",
       "      <th>hint_total</th>\n",
       "      <th>overlap_time</th>\n",
       "      <th>template_id</th>\n",
       "      <th>answer_id</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>first_action</th>\n",
       "      <th>bottom_hint</th>\n",
       "      <th>opportunity</th>\n",
       "      <th>opportunity_original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33022537</td>\n",
       "      <td>277618</td>\n",
       "      <td>64525</td>\n",
       "      <td>33139</td>\n",
       "      <td>51424</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32454</td>\n",
       "      <td>tutor</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32454</td>\n",
       "      <td>30799</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33022709</td>\n",
       "      <td>277618</td>\n",
       "      <td>64525</td>\n",
       "      <td>33150</td>\n",
       "      <td>51435</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4922</td>\n",
       "      <td>tutor</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4922</td>\n",
       "      <td>30799</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35450204</td>\n",
       "      <td>220674</td>\n",
       "      <td>70363</td>\n",
       "      <td>33159</td>\n",
       "      <td>51444</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>25390</td>\n",
       "      <td>tutor</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>42000</td>\n",
       "      <td>30799</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35450295</td>\n",
       "      <td>220674</td>\n",
       "      <td>70363</td>\n",
       "      <td>33110</td>\n",
       "      <td>51395</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4859</td>\n",
       "      <td>tutor</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4859</td>\n",
       "      <td>30059</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35450311</td>\n",
       "      <td>220674</td>\n",
       "      <td>70363</td>\n",
       "      <td>33196</td>\n",
       "      <td>51481</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>19813</td>\n",
       "      <td>tutor</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>124564</td>\n",
       "      <td>30060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id  assignment_id  user_id  assistment_id  problem_id  original  \\\n",
       "0  33022537         277618    64525          33139       51424         1   \n",
       "1  33022709         277618    64525          33150       51435         1   \n",
       "2  35450204         220674    70363          33159       51444         1   \n",
       "3  35450295         220674    70363          33110       51395         1   \n",
       "4  35450311         220674    70363          33196       51481         1   \n",
       "\n",
       "   correct  attempt_count  ms_first_response tutor_mode  ... hint_count  \\\n",
       "0        1              1              32454      tutor  ...          0   \n",
       "1        1              1               4922      tutor  ...          0   \n",
       "2        0              2              25390      tutor  ...          0   \n",
       "3        1              1               4859      tutor  ...          0   \n",
       "4        0             14              19813      tutor  ...          3   \n",
       "\n",
       "   hint_total  overlap_time  template_id answer_id  answer_text  first_action  \\\n",
       "0           3         32454        30799       NaN           26             0   \n",
       "1           3          4922        30799       NaN           55             0   \n",
       "2           3         42000        30799       NaN           88             0   \n",
       "3           3          4859        30059       NaN           41             0   \n",
       "4           4        124564        30060       NaN           65             0   \n",
       "\n",
       "  bottom_hint  opportunity  opportunity_original  \n",
       "0         NaN            1                   1.0  \n",
       "1         NaN            2                   2.0  \n",
       "2         NaN            1                   1.0  \n",
       "3         NaN            2                   2.0  \n",
       "4         0.0            3                   3.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋 경로 설정 (실제 경로로 변경하세요)\n",
    "data_path = 'datasets/ASSIST2009/skill_builder_data.csv'\n",
    "\n",
    "# 데이터 로드\n",
    "data = pd.read_csv(data_path, encoding='ISO-8859-1', low_memory=False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-preprocessing",
   "metadata": {},
   "source": [
    "### 데이터 전처리\n",
    "\n",
    "모델 학습에 필요한 형태로 데이터를 전처리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "data-preprocess-code",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학생 수: 4217\n",
      "문제 수: 26688\n"
     ]
    }
   ],
   "source": [
    "# 필요한 컬럼 선택\n",
    "data = data[['user_id', 'problem_id', 'correct']]\n",
    "\n",
    "# 결측치 제거\n",
    "data = data.dropna()\n",
    "\n",
    "# ID 인코딩\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "user_encoder = LabelEncoder()\n",
    "data['user_id'] = user_encoder.fit_transform(data['user_id'])\n",
    "\n",
    "item_encoder = LabelEncoder()\n",
    "data['problem_id'] = item_encoder.fit_transform(data['problem_id'])\n",
    "\n",
    "# 문제 수와 학생 수 확인\n",
    "num_students = data['user_id'].nunique()\n",
    "num_questions = data['problem_id'].nunique()\n",
    "\n",
    "print(f'학생 수: {num_students}')\n",
    "print(f'문제 수: {num_questions}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sequence-generation",
   "metadata": {},
   "source": [
    "### 시퀀스 데이터 생성\n",
    "\n",
    "학생별로 문제 풀이 이력을 시퀀스로 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sequence-gen-code",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 시퀀스 수: 4217\n"
     ]
    }
   ],
   "source": [
    "# 학생별로 그룹화\n",
    "grouped = data.groupby('user_id')\n",
    "\n",
    "# 시퀀스 생성\n",
    "sequences = []\n",
    "\n",
    "for _, group in grouped:\n",
    "    seq = list(zip(group['problem_id'].values, group['correct'].values))\n",
    "    sequences.append(seq)\n",
    "\n",
    "print(f'총 시퀀스 수: {len(sequences)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dataset-dataloader",
   "metadata": {},
   "source": [
    "### Dataset 및 DataLoader 구성\n",
    "\n",
    "모델 학습을 위한 PyTorch Dataset과 DataLoader를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dataset-code",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DKTDataset(Dataset):\n",
    "    def __init__(self, sequences, num_questions, seq_len=100):\n",
    "        self.sequences = sequences\n",
    "        self.num_questions = num_questions\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.sequences[idx]\n",
    "        \n",
    "        seq = seq[-self.seq_len:]\n",
    "        \n",
    "        x = np.zeros(self.seq_len, dtype=int)\n",
    "        y = np.zeros(self.seq_len, dtype=int)\n",
    "        \n",
    "        for i, (q, r) in enumerate(seq):\n",
    "            x[i] = q + self.num_questions * r\n",
    "            y[i] = q\n",
    "        \n",
    "        return torch.tensor(x, dtype=torch.long), torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "# 데이터셋 생성\n",
    "dataset = DKTDataset(sequences, num_questions)\n",
    "\n",
    "# 훈련셋과 테스트셋 분할\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# DataLoader 생성\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "define-model",
   "metadata": {},
   "source": [
    "## DKT 모델 아키텍처\n",
    "DKT 모델은 다음과 같은 구조로 이루어져 있습니다:\n",
    "1. 임베딩 층: 문제 ID를 벡터로 변환\n",
    "2. LSTM 층: 시퀀스 데이터 처리\n",
    "3. 출력 층: 다음 문제 정답 확률 예측\n",
    "\n",
    "DKT 모델은 LSTM(Long Short-Term Memory) 신경망을 기반으로 하며, 학생의 과거 문제 풀이 이력을 입력으로 받아 다음 문제의 정답 확률을 예측합니다. LSTM을 기반으로 한 DKT 모델을 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "model-definition",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DKTModel(nn.Module):\n",
    "    def __init__(self, num_questions, hidden_size):\n",
    "        super(DKTModel, self).__init__()\n",
    "        self.num_questions = num_questions\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(num_questions * 2, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_questions)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        embed = self.embedding(x)\n",
    "        h, _ = self.lstm(embed)\n",
    "        out = self.fc(h)\n",
    "        preds = torch.sigmoid(out)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train-model",
   "metadata": {},
   "source": [
    "## 모델 학습\n",
    "\n",
    "모델을 학습시키는 코드를 작성합니다. 학습 과정에서 고려할 사항들:\n",
    "- 배치 크기 선택\n",
    "- 학습률 조정\n",
    "- 손실 함수 (BCE Loss)\n",
    "- 옵티마이저 (Adam)\n",
    "- 에포크 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "train-code",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.6603\n",
      "Epoch [2/10], Loss: 0.5177\n",
      "Epoch [3/10], Loss: 0.2917\n",
      "Epoch [4/10], Loss: 0.1760\n",
      "Epoch [5/10], Loss: 0.1177\n",
      "Epoch [6/10], Loss: 0.0840\n",
      "Epoch [7/10], Loss: 0.0631\n",
      "Epoch [8/10], Loss: 0.0489\n",
      "Epoch [9/10], Loss: 0.0390\n",
      "Epoch [10/10], Loss: 0.0319\n"
     ]
    }
   ],
   "source": [
    "# 디바이스 설정 (INF2에서는 CPU로 설정)\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "num_epochs = 10\n",
    "hidden_size = 100\n",
    "\n",
    "# 모델 초기화\n",
    "model = DKTModel(num_questions, hidden_size).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 학습 루프\n",
    "train_losses = []\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for x, y in train_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(x)\n",
    "        \n",
    "        # 타깃 생성\n",
    "        target_mask = (y != 0)\n",
    "        target_indices = y[target_mask]\n",
    "        \n",
    "        preds = preds[target_mask, target_indices]\n",
    "        targets = (x[target_mask] >= num_questions).float()\n",
    "        \n",
    "        loss = criterion(preds, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "\n",
    "# 학습된 모델 저장\n",
    "torch.save(model.state_dict(), 'dkt_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compile-model",
   "metadata": {},
   "source": [
    "## 모델 컴파일 (Neuron 최적화)\n",
    "\n",
    "학습된 모델을 INF2에서 추론할 수 있도록 `torch_neuronx`를 사용하여 컴파일합니다.\n",
    "\n",
    "예시 입력(example_inputs)을 생성하는 이유는 다음과 같습니다:\n",
    "\n",
    "1. **모델 컴파일을 위한 입력 형태 정의**\n",
    "   - torch_neuronx.trace() 함수는 모델을 AWS Inferentia2에 최적화된 형태로 컴파일하기 위해 입력 텐서의 구체적인 형태(shape)와 데이터 타입을 알아야 합니다.\n",
    "   - 예시 입력을 통해 모델이 실제로 받게 될 데이터의 구조를 미리 알려주는 것입니다.\n",
    "\n",
    "2. **컴파일 최적화**\n",
    "   ```python\n",
    "   example_inputs = torch.randint(0, num_questions * 2, (batch_size, 100), dtype=torch.long)\n",
    "   ```\n",
    "   - batch_size: 한 번에 처리할 데이터 수 (여기서는 64)\n",
    "   - 100: 시퀀스 길이\n",
    "   - num_questions * 2: 가능한 입력값의 범위 (문제 ID와 정답 여부 조합)\n",
    "\n",
    "3. **실행 그래프 생성**\n",
    "   - 컴파일러는 이 예시 입력을 사용하여 모델의 연산 그래프를 최적화합니다.\n",
    "   - 실제 추론 시에 사용될 연산 패턴을 미리 분석하고 최적화합니다.\n",
    "\n",
    "4. **하드웨어 최적화**\n",
    "   ```python\n",
    "   model_neuron = torch_neuronx.trace(model, example_inputs)\n",
    "   ```\n",
    "   - AWS Inferentia2 하드웨어에 맞게 연산을 최적화합니다.\n",
    "   - 메모리 사용량과 연산 속도를 개선합니다.\n",
    "\n",
    "예시:\n",
    "```python\n",
    "# 실제 배치 크기가 64이고, 시퀀스 길이가 100인 경우\n",
    "batch_size = 64\n",
    "seq_length = 100\n",
    "num_questions = 100  # 전체 문제 수\n",
    "\n",
    "# 예시 입력 생성\n",
    "example_inputs = torch.randint(\n",
    "    low=0,  # 최소값\n",
    "    high=num_questions * 2,  # 최대값 (문제 수 * 2)\n",
    "    size=(batch_size, seq_length),  # 입력 텐서의 크기\n",
    "    dtype=torch.long  # 데이터 타입\n",
    ")\n",
    "\n",
    "# 이 예시 입력으로 모델 컴파일\n",
    "model_neuron = torch_neuronx.trace(model, example_inputs)\n",
    "```\n",
    "\n",
    "이렇게 생성된 예시 입력은 실제 데이터가 아닌 더미 데이터이지만, 모델 컴파일과 최적화에 필요한 모든 구조적 정보를 포함하고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "compile-code",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-25 14:22:00.000511:  18793  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-11-25 14:22:00.000512:  18793  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: ['neuronx-cc', '--target=trn1', 'compile', '--framework', 'XLA', '/tmp/ec2-user/neuroncc_compile_workdir/f1751cb8-0a67-4cb8-bc6a-c417a2e51eee/model.MODULE_10466109672838001554+d41d8cd9.hlo.pb', '--output', '/tmp/ec2-user/neuroncc_compile_workdir/f1751cb8-0a67-4cb8-bc6a-c417a2e51eee/model.MODULE_10466109672838001554+d41d8cd9.neff', '--verbose=35']\n",
      ".\n",
      "Compiler status PASS\n",
      "2024-11-25 14:22:02.000881:  18863  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-11-25 14:22:02.000882:  18863  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: ['neuronx-cc', '--target=trn1', 'compile', '--framework', 'XLA', '/tmp/ec2-user/neuroncc_compile_workdir/20158125-f6fd-4581-b4a0-c79305a82d2d/model.MODULE_10076059576887794638+d41d8cd9.hlo.pb', '--output', '/tmp/ec2-user/neuroncc_compile_workdir/20158125-f6fd-4581-b4a0-c79305a82d2d/model.MODULE_10076059576887794638+d41d8cd9.neff', '--verbose=35']\n",
      ".\n",
      "Compiler status PASS\n",
      "2024-11-25 14:22:04.000456:  18927  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-11-25 14:22:04.000457:  18927  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: ['neuronx-cc', '--target=trn1', 'compile', '--framework', 'XLA', '/tmp/ec2-user/neuroncc_compile_workdir/7deb959a-dcb1-484b-83d2-b0474aaf9a39/model.MODULE_12064476461908315021+d41d8cd9.hlo.pb', '--output', '/tmp/ec2-user/neuroncc_compile_workdir/7deb959a-dcb1-484b-83d2-b0474aaf9a39/model.MODULE_12064476461908315021+d41d8cd9.neff', '--verbose=35']\n",
      ".\n",
      "Compiler status PASS\n",
      "2024-11-25 14:22:06.000086:  18997  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-11-25 14:22:06.000087:  18997  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: ['neuronx-cc', '--target=trn1', 'compile', '--framework', 'XLA', '/tmp/ec2-user/neuroncc_compile_workdir/64915eb1-3194-40c0-b6e7-4d1e75838fad/model.MODULE_12957766554152477008+d41d8cd9.hlo.pb', '--output', '/tmp/ec2-user/neuroncc_compile_workdir/64915eb1-3194-40c0-b6e7-4d1e75838fad/model.MODULE_12957766554152477008+d41d8cd9.neff', '--verbose=35']\n",
      ".\n",
      "Compiler status PASS\n",
      "2024-11-25 14:22:07.000771:  19052  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-11-25 14:22:07.000772:  19052  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: ['neuronx-cc', '--target=trn1', 'compile', '--framework', 'XLA', '/tmp/ec2-user/neuroncc_compile_workdir/87359081-869d-4e48-aa93-d06c036b3e20/model.MODULE_16164033684040262538+d41d8cd9.hlo.pb', '--output', '/tmp/ec2-user/neuroncc_compile_workdir/87359081-869d-4e48-aa93-d06c036b3e20/model.MODULE_16164033684040262538+d41d8cd9.neff', '--verbose=35']\n",
      ".\n",
      "Compiler status PASS\n",
      ".....\n",
      "Compiler status PASS\n"
     ]
    }
   ],
   "source": [
    "# 모델 로드\n",
    "model.load_state_dict(torch.load('dkt_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# 예시 입력 생성\n",
    "example_inputs = torch.randint(0, num_questions * 2, (batch_size, 100), dtype=torch.long)\n",
    "\n",
    "# Neuron으로 컴파일\n",
    "model_neuron = torch_neuronx.trace(model, example_inputs)\n",
    "\n",
    "# 컴파일된 모델 저장\n",
    "model_neuron.save('dkt_model_neuron.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inference",
   "metadata": {},
   "source": [
    "## 성능 평가\n",
    "\n",
    "컴파일된 모델을 사용하여 INF2에서 추론을 수행합니다. DKT 모델의 성능은 다음 지표로 평가됩니다:\n",
    "- AUC (Area Under the ROC Curve)\n",
    "- 정확도 (Accuracy)\n",
    "- 손실 함수 값의 변화\n",
    "\n",
    "AWS Inferentia 하드웨어에서 모델을 실행할 때는 입력 텐서의 크기가 컴파일 시 지정된 크기와 정확히 일치해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "inference-code",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[테스트 통계]\n",
      "총 시퀀스 수: 832\n",
      "총 문제 수: 35537\n",
      "시퀀스당 평균 문제 수: 42.71\n",
      "전체 데이터 크기: 35537\n",
      "\n",
      "테스트 성능:\n",
      "AUC: 99.17%\n"
     ]
    }
   ],
   "source": [
    "# 컴파일된 모델 로드\n",
    "model_neuron = torch.jit.load('dkt_model_neuron.pt')\n",
    "model_neuron.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "total_samples = 0\n",
    "total_sequences = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (x, y) in enumerate(test_loader):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        preds = model_neuron(x)\n",
    "        \n",
    "        batch_samples = 0\n",
    "        for i in range(len(y)):\n",
    "            target_mask = (y[i] != 0)\n",
    "            target_indices = y[i][target_mask]\n",
    "            pred = preds[i][target_mask, target_indices]\n",
    "            \n",
    "            # 현재 시퀀스의 실제 문제 수 계산\n",
    "            num_problems = len(target_indices)\n",
    "            batch_samples += num_problems\n",
    "            \n",
    "            all_preds.extend(pred.cpu().numpy())\n",
    "            all_targets.extend((x[i][target_mask] >= num_questions).cpu().numpy())\n",
    "        \n",
    "        total_samples += batch_samples\n",
    "        total_sequences += len(y)\n",
    "\n",
    "print(f'\\n[테스트 통계]')\n",
    "print(f'총 시퀀스 수: {total_sequences}')\n",
    "print(f'총 문제 수: {total_samples}')\n",
    "print(f'시퀀스당 평균 문제 수: {total_samples/total_sequences:.2f}')\n",
    "print(f'전체 데이터 크기: {len(all_preds)}')\n",
    "\n",
    "# 성능 평가\n",
    "auc = roc_auc_score(all_targets, all_preds)\n",
    "print(f'\\n테스트 성능:')\n",
    "print(f'AUC: {auc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## 결론\n",
    "\n",
    "이 노트북에서는 DKT 모델을 PyTorch와 AWS Inferentia2를 사용하여 구현하고, `torch-neuronx`를 통해 INF2에서 추론을 수행했습니다. 초보자도 이해할 수 있도록 단계별로 설명하였으며, INF2의 성능을 활용하여 효율적인 추론을 달성할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "references",
   "metadata": {},
   "source": [
    "## 참고 자료\n",
    "\n",
    "- [Deep Knowledge Tracing 논문](https://papers.nips.cc/paper/2015/file/efc3f4b5768f887a677ce7f1dba75504-Paper.pdf)\n",
    "- [ASSISTments 데이터셋](https://sites.google.com/site/assistmentsdata/home/assistment-2009-2010-data)\n",
    "- [AWS Neuron SDK 문서](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/neuron-guide/neuron-frameworks/pytorch-neuronx/tutorials/torch-neuronx.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_neuron_pytorch_p38",
   "language": "python",
   "name": "conda_neuron_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
